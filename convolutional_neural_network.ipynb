{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MelihKlc/Machine-Learning/blob/main/convolutional_neural_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DR-eO17geWu"
      },
      "source": [
        "# Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMefrVPCg-60"
      },
      "source": [
        "### Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCV30xyVhFbE"
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator  #for image preprocessing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIleuCAjoFD8"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxQxCBWyoGPE"
      },
      "source": [
        "## Part 1 - Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvE-heJNo3GG"
      },
      "source": [
        "### Preprocessing the Training set"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255, #her pixeli 255 e bölerek feature scaling yapıyor.(compulsary)\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True) #overfitting olmaması için sadece training sette bir transformation yapmamız gerek. Bu transformationlara image augmentation diyoruz.\n",
        " training_set = train_datagen.flow_from_directory('dataset/training_set', #training sete bağlıyoruz flow_from_directory ile augment edilmiş image leri\n",
        "                                                 target_size = (64, 64), #final size of our images\n",
        "                                                 batch_size = 32, #her batch de kaç image olacak onu belirliyoruz.\n",
        "                                                 class_mode = 'binary')    #we have binary outcome, cat or dog"
      ],
      "metadata": {
        "id": "f20rdBSa5CeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrCMmGw9pHys"
      },
      "source": [
        "### Preprocessing the Test set"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen = ImageDataGenerator(rescale = 1./255) #her zaman yaptığımız gibi normalde de test setlere sadece transformation uyguluyoduk fit uygulamıyoduk verileri bozmamak için burda da augment yapmıcaz teste çünkü original fotoların bozulmasını istemiyoruz. Fakat feature scaling yapıyoruz çünkü biliyoruz ki yine önceden verilerin scale i aynı olmalı. Train sette scaleing yaptıgımız icin burda da yapıyoruz.\n",
        "test_set = test_datagen.flow_from_directory('dataset/test_set',\n",
        "                                            target_size = (64, 64),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'binary')"
      ],
      "metadata": {
        "id": "0GhHIS14-HdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af8O4l90gk7B"
      },
      "source": [
        "## Part 2 - Building the CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ces1gXY2lmoX"
      },
      "source": [
        "### Initialising the CNN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = tf.keras.models.Sequential()  #sequential layerlar kullanacağımız için onları bununla oluşturuyoruz."
      ],
      "metadata": {
        "id": "2i3NUcGc_wiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5YJj_XMl5LF"
      },
      "source": [
        "### Step 1 - Convolution"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters = 32 , kernel_size = 3 , activation = 'relu' , input_shape[64,64,3] ))  #add methodunu layer eklemek için kullanıyoruz.filters yani feature detector sayısını belirlicez. kernel size da aslında feature filtersin dağılım şekli eğer 3 seçersek 3x3 matrix oluşuyo. bir de input shape belirlicez onu da üstte 64x64 belirlediğimiz için 64 64 3 giricez 3 te biz renkli resim kullandığımız için RGB olarak 3 belirliyoruz 3 boyut.\n",
        "#filters genel olarak 32 seçiliyor. activation olarak da rectifier seçiyoruz"
      ],
      "metadata": {
        "id": "MCM1uGY2GTSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tf87FpvxmNOJ"
      },
      "source": [
        "### Step 2 - Pooling"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size = 2 , strides = 2)) #max pool kullanıyoruz ve 2x2 seçiyoruz poolsize parametresiyle. strides parametresiyle de kaç pixel atlayıp pooling mapimizi oluşturuyoruz onu seçiyoruz. padding parametresinde valid dersek mesela en sağda 2 pixel giriyo sadece içine poolun sadece o 2 pixele göre işlem yapıyor. eğer same seçersek boş olan 2 pixeli fake pixellerle 0 larla yani dolduruyor."
      ],
      "metadata": {
        "id": "Lt1XcltRGXpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaTOgD8rm4mU"
      },
      "source": [
        "### Adding a second convolutional layer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters = 32 , kernel_size = 3 , activation = 'relu'  ))  #add methodunu layer eklemek için kullanıyoruz.filters yani feature detector sayısını belirlicez. kernel size da aslında feature filtersin dağılım şekli eğer 3 seçersek 3x3 matrix oluşuyo. bir de input shape belirlicez onu da üstte 64x64 belirlediğimiz için 64 64 3 giricez 3 te biz renkli resim kullandığımız için RGB olarak 3 belirliyoruz 3 boyut.\n",
        "#filters genel olarak 32 seçiliyor. activation olarak da rectifier seçiyoruz. sadece first conv layer direkt olarak inputa geçtiği için ikincide input shape belirlememize gerek yok\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size = 2 , strides = 2))"
      ],
      "metadata": {
        "id": "kGxrirAIGlqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmiEuvTunKfk"
      },
      "source": [
        "### Step 3 - Flattening"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Flatten()) #bu input oluyor artık bu inputu da full connectiona bağlıcaz."
      ],
      "metadata": {
        "id": "M4VwgO02IYxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAoSECOm203v"
      },
      "source": [
        "### Step 4 - Full Connection"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dense(units = 128 , activation = 'relu')) #unitsle neuron sayısını seçtik layerin içindeki."
      ],
      "metadata": {
        "id": "XeWM9L03I6AU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTldFvbX28Na"
      },
      "source": [
        "### Step 5 - Output Layer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dense(units = 1 , activation = 'sigmoid'))  #şimdi outputlarımız kedi ve köpek olduğu için sonucunda 1 köpek 0 kedi olarak belirlenirse 1 output çıkacak 1 çıkarsa biz bu köpek dicez o yüzden units 1 seçtik.\n",
        "#eğer multiclass classification yapsaydık softmax activation kullanmamız gerekiyodu burda binary classification kullandığımız için sigmoid kullanıyoruz."
      ],
      "metadata": {
        "id": "KIVBkDtPKlEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6XkI90snSDl"
      },
      "source": [
        "## Part 3 - Training the CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfrFQACEnc6i"
      },
      "source": [
        "### Compiling the CNN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.compile(optimizer = 'adam' , loss = 'binary_crossentropy' , metrics = ['accuracy'] ) #burda optimizere ve loss functiona bağlıcaz cnn i. adam optimizer seçiyoruz stochastic gradient descent yani erroru azaltmak için. loss olarak da cross entropy seçicez"
      ],
      "metadata": {
        "id": "32fyVrZ_L8Lb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehS-v3MIpX2h"
      },
      "source": [
        "### Training the CNN on the Training set and evaluating it on the Test set"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.fit( x = training_set , y = test_set , validation_data = test_set , epochs = 25) #we are not only training the CNN on the training set but also evaluating it at the same time on the test set bunun için de validation data kulanıyoruz.\n",
        "#datasetimizin size ı çok büyük oldugu icin colabta çalışmıyor bu yüzden jupyterde run yapıcaz."
      ],
      "metadata": {
        "id": "5mnVSGHNNMre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3PZasO0006Z"
      },
      "source": [
        "## Part 4 - Making a single prediction"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "test_image = image.load_img('dataset/single_prediction/cat_or_dog_1.jpg' , target_size = (64,64))  #burda image yüklüyoruz. training sette ne belirlediysek size ı burda da aynısını belirlememiz gerekiyor.\n",
        "test_image = image.img_to_array(test_image) #predict method kullanıcaz ve her zamanki gibi predict method 2d array almak zorunda oldugu icin 2d array yapıcaz image i bunu da img_to_array ile sağlıyoruz.\n",
        "test_image = np.expand_dims(test_image , axis = 0) #fake dimension or dimension corresponding to the batch. dimension of the batch is always first dimension bu yüzden axisi 0 seçicez yani biz batch e image eklicez ve batch in dimension ını first dimension\n",
        "result = cnn.predict(test_image)\n",
        "training_set.class.indices #1 köpeği mi belirtiyor kediyi mi bilmiyoruz bunun için bu kodu yazdık ve köpek 1 kedi 0 olacak.\n",
        "if result[0][0] == 1:  #result contains also actually the result into a batch because it was called on a test_image that was into a batch so results also has this batch dimension. result[0] diyoruz çünkü sadece 1 batch var ve onun da indexi 0 and then inside the batch we are gonna get access to the first and only element of the batch which corresponds to the prediction of that same car_or_dog_1 image which corresponds 0\n",
        "  prediction = 'dog'\n",
        "else:\n",
        "  prediction = 'cat'\n"
      ],
      "metadata": {
        "id": "ooE3zLPqPMC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prediction)"
      ],
      "metadata": {
        "id": "D9r39t4BWiVK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}